---
title: "inc04a"
author: "Ji H. Kang"
date: "10/19/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lists are atomic 

```{r}
a <- 1:3 
a
```

```{r}
a + 1
a*2
```

```{r}
l <- list(1:3, "xyz", TRUE) 
l 
```
```{r}
a[2] #Extract element from vector with []
```
```{r}
l[[1]] #for lists, use double brackets 
```
Use pipes: 
```{r, message=FALSE}
library(dplyr) 
l %>% 
  "[["(2) #Same as l[[2]]
```

# String functions 

Search for a pattern: 'grep' 
```{r}
names <- c("Li Gong", "Li Zhao", "Ma Lane") 
grep("Li", names) #Doing grep("Li", names, value=TRUE) returns the elements instead. 
```

## Exercise: 

Consider 3 sentences: 
* I will help you to catch him 
* Bring four men with you
* Do not sleep tonight 

Extract the sentence that contains "sleep"! 
```{r}
sentences <- c("I will help you to catch him", "Bring four men with you", 
               "Do not sleep tonight ")
grep("sleep", sentences, value=TRUE)
```




## Tokenize with strsplit 

```{r}
sentences <- c("The watchman nodded.", "The monk led five men to a gog gate")
strsplit(sentences, " ")
```

```{r}
sentence <- "Tonight, between third and fifth watch, I intend to catch the thief"
words <- strsplit(sentence, " ")[[1]] #Extract first element only
pos <- which(words == "watch,")
pos
```

```{r}
words[pos-1]
words[pos+1]
```

```{r}
sentences <- c("I will help you to catch him", "Bring four men with you",              "Do not sleep tonight")
sleepy <- grep("sleep", sentences, value=TRUE) %>%  # find sentence  
  strsplit(" ") %>%   # split into words  
  "[["(1)  # get 1st component -> words
sleepy
pos <- which(sleepy == "sleep")
pos
cat("the preceding word:", sleepy[pos-1], "\n")
```

# Web scraping 
```{r}
library(rvest)
monk <- read_html("/Users/jaydenk/Downloads/scrape-example.html")
```

## Extract the title 
```{r}
monk %>% 
  html_node("title") %>% 
  html_text()
```
 Extract the first paragraph
 
```{r}
p1 <- monk %>% 
  html_node("p") #Extract the first paragraph 
p1 %>% 
  html_text() %>% #print in human readable form 
  cat()
```

Extract paragraph of class "quote": 
```{r}
Pquote <- monk %>% 
  html_node("p.quote") 
Pquote %>% 
  html_text() %>% 
  cat()
```
Extract text from all paragraphs:
Note: They are lists 
```{r}
Ps <- monk %>% 
  html_nodes("p")

for (P in Ps) {
  P %>% 
    html_text() %>% 
    cat()
  cat("\n---\n") #To separate each paragraph from each other
}
```
Extract individual elements from the list: 
```{r}
Ps[[2]] %>% html_text() %>% cat()
```

Can also use the '[[(2)' trick 
```{r}
P2 <- monk %>% 
  html_nodes("p") %>% 
  "[["(2) 
P2
```
Loop using numeric index: 
```{r}
for (i in 1:length(Ps)) {
  cat("Paragraph", i, "\n")
  Ps[[i]] %>% 
    html_text() %>% 
    cat() 
  cat("\n----\n")
}
```
# HTML Attributes 

## Execise: Extract A (anchor == links) element. Print its text. 
```{r}
A <- monk %>% 
  html_node("p") %>%
  html_nodes("a")
A %>% 
  html_text %>%
  cat() 

```
```{r}
A %>% 
  html_attr("href") %>% cat()
```
## Extract number of articles in English wiki
Load from internet and cache in memory 
```{r}
url <- "https://en.wikipedia.org/wiki/Main_Page"
wiki <- read_html(url)
#div id=articlecount 
```
Now we work with the results 
```{r}
wiki %>% #div.articlecount is for 'class'. div#articlcount is for 'id'
  html_node("div#articlecount") %>%  # the '#' means "id". So div id=articlecount = this
  html_node("a") %>% #extract the 1st A that contains the number 
  html_text() %>% 
  cat("\n")
```





















































