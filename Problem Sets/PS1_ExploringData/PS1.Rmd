---
title: "PS1_ExploringData"
author: "Ji H. Kang"
date: "10/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1.1 Computing 

### Question 1: Compute how many seconds are there in a year and assign it to a suitable variable. Thereafter print the result. 
```{r}
SIH <- 60 * 60 #Seconds in an hour. 60 minutes in an hour
cat("There are", prettyNum(SIH, big.mark=",", scientific=FALSE), "seconds in an hour.\n")
SID <- SIH * 24 #Seconds in a day. #24 hours in a day
cat("There are", prettyNum(SID, big.mark=",", scientific=FALSE), "seconds in a day.\n")
SIW <- SID * 7 #Seconds in a week. 7 Days in a week
cat("There are", prettyNum(SIW, big.mark=",", scientific=FALSE), "seconds in a week.\n")
SIY <- SIW * 52 #Seconds in a year. 52 weeks in a year 
cat("There are", prettyNum(SIY, big.mark=",", scientific=FALSE), "seconds in a year.\n")
```

### Question 2: How long is a typical human lifetime in seconds? Use the seconds-in-year variable you created above to compute it. 
```{r}
cat("The average human lifespan is 79 years according to google...\n")
SILT <- SIY * 79 #Seconds-in-lifetime
cat("There are approximately", prettyNum(SILT, big.mark=",", scientific=FALSE), "seconds in a human lifetime.\n")
```

### Question 3: The age of the Universe is 13.7 billion years. How old is the Universe in seconds?
```{r}
universeAge <- 13700000000 #13.7 billion 
universeAgeInSeconds <- universeAge * SILT 
cat("The Universe is", prettyNum(universeAgeInSeconds, big.mark=",", scientific=FALSE), "seconds old.\n")
```

# 1.2 Functions 

### Question 1: Write a function that takes two arguments: first name, and last name; and returns a sentence like "Hi, my name is *first name* *last name*, nice to meet you!". 
```{r}
greetPerson <- function(first_name="", last_name="") {
  return(sprintf("Hi, my name is %s %s, nice to meet you!", first_name, last_name))
}
print(greetPerson("Ji-Hoon", "Kang"))
```


# 1.3 Vectors, loops, if/else 
### Setting up the vector 
```{r}
set.seed(1) 
v <- sample(10, 20, replace=TRUE) - 5 
v
```
### Question 1: Use a for-loop to extract only positive numbers from this vector 
```{r}
positiveV <- c() #Empty vector 
for (number in v){
  if (number > 0) {
    positiveV <- c(positiveV, number)
  }
}
positiveV
```
### Not part of the assignment but can also do something like this 
```{r}
newV <- v[which(v > 0)]
newV
```

### Question 2: Perform the same task without a for-loop using logical indexing 
```{r}
logicalIndexes <- v > 0 
positiveV <- v[logicalIndexes] #Overwrite the previous vector
positiveV
```

```{r}
v1 <- 9
v2 <- c(1,2)
v3 <- c(2,3,-4)
```
### Question 3: Write a function that tests if the vectors have negative elements, and prints an appropriate message. Test the negativity of these three vectors to show the function works correctly. 
```{r}
containsNegative <- function(vec = NULL){
  if (is.null(vec)){
    print("No given vector or was NULL. Please try with a diff argument")
  } else {
    if (all(vec >= 0)){
      print("There are no negative values in this vector!")
    } else {
      print("There are negative values in this vector!")
    }
  }
}
```

```{r}
cat("v1 contains:", v1)
containsNegative(v1) 
cat("v2 contains:", v2)
containsNegative(v2) 
cat("v3 contains:", v3)
containsNegative(v3) 
```

# 2 Data Exploration 
```{r}
#install.packages("nycflights13") #Uncomment if package is not installed. 
data(flights, package="nycflights13")
#names(flights)
```


# 2.1 Exploring the NYC Flights Data 

### Question 2: Perform basic inspections of the data 
* How many distinct flights do we have in the dataset? 
```{r}
nrow(flights)
```
* What are the variables (variable names) in the data? 
```{r}
names(flights)
```
* How many missing values are there in each variable? 
```{r}
#Methodology for this was from https://sebastiansauer.github.io/sum-isna/
library(tidyverse) 
map(flights, ~sum(is.na(.)))
```

## Any unreasonable values? 

### Minimum of each column
```{r}
apply(flights, 2, function(x) min(x, na.rm = TRUE))
```
### Maximum of each column
```{r}
apply(flights, 2, function(x) max(x, na.rm = TRUE))
```
### Range of each column
```{r}
apply(flights, 2, function(x) range(x, na.rm = TRUE))
```
#### Upon initial analysis of the data, nothing seems out of the ordinary except for delays in either arrival or departure times - however, delays in airport flights happen all the time to the point where it may even be delayed... even up to past a week due to natural factors such as snow storms. 
#### Initially, having a minimum flight distance of 17 miles is underwhelming. Are there really flights that span only 17 miles? Could this be across water?



# 3. Formulate a reasonable question about this dataset: 
#### Question: Which airport from the data set, on average, has the largest **departure delays** for flights that are leaving from them in 2013. Eg. Flights from JFK would have a **'origin'** value of JFK. 

# 4. Explore Data

### Here are the available airports in this data set
```{r}
unique(flights$origin)
```

### Which variables are the most important ones from the question's perspective. 
From the standpoint of the question, the only important variables to consider for this approach are the **origin** to get the airport, and **dep_delay** for the departure delay times for those records.

### Splitting up the data set by airport origin 
```{r}
airport_split <- split(flights, flights$origin) # Split data set based on the origin 
# Each airport is split based on their origin airport 
EWR <- airport_split$EWR
JFK <- airport_split$JFK 
LGA <- airport_split$LGA
```

### Inspecting the data
#### We see from section 2.1 that there are no missing values for origin. So we should focus on seeing how many values for dep_delay there are for each airport. 
### JFK
```{r}
sum(is.na(JFK$dep_delay))
```
### LGA 
```{r}
sum(is.na(LGA$dep_delay))
```
### EWR
````{r}
sum(is.na(EWR$dep_delay))
```
#### We can see JFK has 1863 missing, LGA has 3153, and EWR has 3239. We'll have to exclude these records from our analysis. 
```{r}
#If the dep_delay is NA for these, it will get rid of them via logical indexing. 
EWR <- EWR[!is.na(EWR$dep_delay),]
JFK <- JFK[!is.na(JFK$dep_delay),]
LGA <- LGA[!is.na(LGA$dep_delay),]
```
#### Airport travels are always riddled with delays, layovers, and unforeseen circumstances where a passenger may find themself waiting or missing an early departure flight. Doing this simple analysis will give some reassurance to passengers.

```{r}
#Don't need na.rm=TRUE since the individual subsets have been cleaned of records with a dep_delay of NA. 
JFK_avg <- round(mean(JFK$dep_delay), digits = 2) 
EWR_avg <- round(mean(EWR$dep_delay), digits = 2)
LGA_avg <- round(mean(LGA$dep_delay), digits = 2)
cat(paste("The average delay time for JFK is", JFK_avg, "minutes, EWR is", EWR_avg, "minutes, and LGA is", LGA_avg, "minutes."))
```
```{r}
avgs <- matrix(c(JFK_avg, EWR_avg, LGA_avg), ncol=1, byrow=TRUE)
labels <- c("JFK", "EWR", "LGA")
rownames(avgs) <- c("JFK", "EWR", "LGA")
colnames(avgs) <- "Delay (minutes)"
table_var <- as.table(avgs)
table_var
```
# 5. Conclusion 

We can see that EWR has an average delay of 15.11 minutes with JFK and LGA trailing with 12.11 minutes and 10.35 minutes respectively. 

Within the realm of this dataset, we can conclude that no matter which airport you choose, you can expect to wait at least 10 minutes.Passengers may use this data to plan ahead of time. 

Whether they should show up x minutes earlier or can assume they'll be reassured of running late by looking at these averages. 

Another experiment would be to do this across all major airports in the United States with more recent data. No matter how advanced scheduling algorithms, IT solutions, etc. gets it seems that flight delays are still prevalent. 


